{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers, layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Bidirectional, Dense, Dropout, Flatten\n",
    "from keras.layers import GRU, Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up parameter globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_len = 256\n",
    "Routings = 5\n",
    "Num_capsule = 2\n",
    "Dim_capsule = 16\n",
    "dropout_p = 0.3\n",
    "rate_drop_dense = 0.3\n",
    "\n",
    "batch_size = 512\n",
    "recurrent_units = 64\n",
    "dropout_rate = 0.5 \n",
    "dense_size = 20\n",
    "sentences_length = 50\n",
    "fold_count = 10\n",
    "max_features = 20000\n",
    "maxlen = 1000\n",
    "embed_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-linear activation fucntion for capsule layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(tensor, axis):\n",
    "    s_norm = K.sum(K.square(tensor), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_norm + K.epsilon())\n",
    "    return tensor / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the capsule network algorithm with slight tweaks to optimize with the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(layers.Layer):\n",
    "    \n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        \n",
    "        inputs_expand = tf.expand_dims(inputs, 1)\n",
    "        inputs_tiled  = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
    "        inputs_tiled  = tf.expand_dims(inputs_tiled, 4)\n",
    "        \n",
    "        inputs_hat = tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled)     \n",
    "\n",
    "        # Begin: Routing algorithm ----------------------------------------------#\n",
    "        b = tf.zeros(shape=[tf.shape(inputs_hat)[0], self.num_capsule, \n",
    "                            self.input_num_capsule, 1, 1])\n",
    "\n",
    "        assert self.routings > 0, 'The routings should be > 0.'\n",
    "        for i in range(self.routings):\n",
    "            \n",
    "            c = layers.Softmax(axis=1)(b)\n",
    "\n",
    "            outputs = tf.multiply(c, inputs_hat)\n",
    "            outputs = tf.reduce_sum(outputs, axis=2, keepdims=True)\n",
    "            outputs = squash(outputs, axis=-2)  # [None, 10, 1, 16, 1]\n",
    "\n",
    "            if i < self.routings - 1:\n",
    "\n",
    "                outputs_tiled = tf.tile(outputs, [1, 1, self.input_num_capsule, 1, 1])\n",
    "                agreement = tf.matmul(inputs_hat, outputs_tiled, transpose_a=True)\n",
    "                b = tf.add(b, agreement)\n",
    "\n",
    "        # End: Routing algorithm ------------------------------------------------#\n",
    "        \n",
    "        outputs = tf.squeeze(outputs, [2, 4])\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings\n",
    "        }\n",
    "        base_config = super(CapsuleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_replace(domain):\n",
    "\n",
    "    domain = domain.replace(\"ç\", \"c\")\n",
    "    domain = domain.replace(\"Ç\", \"C\")\n",
    "    domain = domain.replace(\"à\", \"a\")\n",
    "    domain = domain.replace(\"Ä\", \"A\")\n",
    "    domain = domain.replace(\"ä\", \"a\")\n",
    "    domain = domain.replace(\"À\", \"A\")\n",
    "    domain = domain.replace(\"Â\", \"A\")\n",
    "    domain = domain.replace(\"â\", \"a\")\n",
    "    domain = domain.replace(\"é\", \"e\")\n",
    "    domain = domain.replace(\"è\", \"e\")\n",
    "    domain = domain.replace(\"É\", \"E\")\n",
    "    domain = domain.replace(\"È\", \"E\")\n",
    "    domain = domain.replace(\"Ë\", \"E\")\n",
    "    domain = domain.replace(\"ë\", \"e\")\n",
    "    domain = domain.replace(\"Ê\", \"E\")\n",
    "    domain = domain.replace(\"ê\", \"e\")\n",
    "    domain = domain.replace(\"û\", \"u\")\n",
    "    domain = domain.replace(\"Û\", \"U\")\n",
    "    domain = domain.replace(\"ü\", \"u\")\n",
    "    domain = domain.replace(\"Ü\", \"U\")\n",
    "    domain = domain.replace(\"ï\", \"i\")\n",
    "    domain = domain.replace(\"Ï\", \"I\")\n",
    "    domain = domain.replace(\"î\", \"i\")\n",
    "    domain = domain.replace(\"Î\", \"I\")\n",
    "    domain = domain.replace(\"Ô\", \"O\")\n",
    "    domain = domain.replace(\"ô\", \"o\")\n",
    "    domain = domain.replace(\"Ö\", \"O\")\n",
    "    domain = domain.replace(\"ö\", \"o\")\n",
    "    domain = domain.replace(\"Ù\", \"U\")\n",
    "    domain = domain.replace(\"ù\", \"u\")\n",
    "    domain = domain.replace(\"ÿ\", \"y\")\n",
    "    domain = domain.replace(\"æ\", \"ae\")\n",
    "    domain = domain.replace(\"_\", \" \")\n",
    "    domain = domain.replace(\"\\n\", \"\")\n",
    "\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading dataset and Tokenizing the host urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = pd.read_csv('Datasets/dga_domains_full.csv', sep = ',')\n",
    "dframe = pd.DataFrame(dframe)\n",
    "df = dframe[[\"host\",\"isDGA\"]]\n",
    "domains = df['host'].apply(lambda domain: char_replace(domain))\n",
    "labels = df['isDGA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = set(' '.join([str(i) for i in domains]))\n",
    "all_letters.add(\"END\")\n",
    "len_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character map creating, saving or loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################\n",
    "#\n",
    "#       Don't run unless training new model        #\n",
    "#\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map = {v: k for k, v in enumerate(all_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_char_map(char_map):\n",
    "    charmap = open('characterMap.pkl','ab')\n",
    "    pickle.dump(char_map,charmap)\n",
    "    charmap.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_char_map(char_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this for testing #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_char_map():\n",
    "    charmap = open('characterMap.pkl','rb')\n",
    "    char_map = pickle.load(charmap)\n",
    "    charmap.close()\n",
    "    return char_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_map = load_char_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(char_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain letter length plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.hist([len(a) for a in domains], bins=36)\n",
    "plt.title(\"Length of the domains\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding the dataset in a character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "# Builds an empty line with a 1 at the index of character\n",
    "def set_flag(i):\n",
    "    temp = np.zeros(len_letters)\n",
    "    temp[i] = 1\n",
    "    return list(temp)\n",
    "\n",
    "# Truncate names and create the matrix\n",
    "def prepare_X(X):\n",
    "    domain_list = []\n",
    "    domain_truncs = [str(i)[0:sentences_length] for i in X]\n",
    "    for i in domain_truncs:\n",
    "        temp = [set_flag(char_map[j]) for j in str(i)]\n",
    "        for k in range(0,sentences_length - len(str(i))):\n",
    "            temp.append(set_flag(char_map[\"END\"]))\n",
    "        domain_list.append(temp)\n",
    "\n",
    "    return domain_list\n",
    "\n",
    "def prepare_y(y):\n",
    "    label_list = []\n",
    "    for i in y:\n",
    "        if i == 'dga':\n",
    "            label_list.append([1,0])\n",
    "        else:\n",
    "            label_list.append([0,1])\n",
    "\n",
    "    return label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepare_X(domains.values)\n",
    "\n",
    "y = prepare_y(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting training and testing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casting train and test lists into numpy arrays of type float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train).astype('float32')\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "y_test = np.asarray(y_test).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(sequence_length, len_letters, dropout_rate, dense_size):\n",
    "    inputs = Input(shape=(sequence_length,len_letters,))\n",
    "    bi = Bidirectional(GRU(gru_len, activation='relu', dropout=dropout_rate, recurrent_dropout=dropout_rate, return_sequences=True),backward_layer=GRU(gru_len, return_sequences=True, go_backwards=True))(inputs)\n",
    "    capsule = CapsuleLayer(num_capsule=Num_capsule, dim_capsule=Dim_capsule)(bi)\n",
    "    capsule = Flatten()(capsule)\n",
    "    capsule = Dropout(dropout_rate)(capsule)\n",
    "    capsule = Dense(dense_size, activation='relu')(capsule)\n",
    "    capsule = Flatten()(capsule)\n",
    "    output = Dense(2, activity_regularizer=l2(0.002), activation='softmax')(capsule)\n",
    "    model = Model(inputs=inputs, outputs=output, name=\"CapsDGA\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoring and model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('capsDGA_model.h5', monitor='accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the model object with the layers loaded in and getting the summary on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgaModel = get_model(sentences_length, len_letters, dropout_rate, dense_size)\n",
    "dgaModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea on the models inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(i.shape, i.dtype) for i in dgaModel.inputs]\n",
    "[print(o.shape, o.dtype) for o in dgaModel.outputs]\n",
    "[print(l.name, l.input_shape, l.dtype) for l in dgaModel.layers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0008)\n",
    "dgaModel.compile( loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting to train models...\")\n",
    "dgaModel.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=batch_size, epochs=40, verbose = 1, callbacks=mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.capsuleLayer import CapsuleLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('capsDGA_model.h5',custom_objects={'CapsuleLayer': CapsuleLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_to_test = [\"mskqpaiq.biz\", \"google.com\", \"appleborderlackentrancedump.com\"]\n",
    "X_pred = prepare_X([char_replace(e) for e in domains_to_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_pred)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = list(prediction)\n",
    "#for i in prediction:\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(domains, prediction):\n",
    "    return_results = []\n",
    "    index = 0\n",
    "    for i in prediction:\n",
    "        if i[0] > i[1]:\n",
    "            return_results.append([domains[index], \"DGA\"])\n",
    "        else:\n",
    "            return_results.append([domains[index], \"Benign\"])\n",
    "        index += 1\n",
    "    return return_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = pred(domains_to_test, prediction)\n",
    "print(len(domains_to_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsacc = []\n",
    "for predings in pred:\n",
    "    if predings[0] > predings[1]:\n",
    "        predsacc.append(1)\n",
    "    else:\n",
    "        predsacc.append(0)\n",
    "\n",
    "predsaccy = []\n",
    "for predings in y_test:\n",
    "    if predings[0] > predings[1]:\n",
    "        predsaccy.append(1)\n",
    "    else:\n",
    "        predsaccy.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsacc = np.asarray(predsacc).astype('float32')\n",
    "predsaccy = np.asarray(predsaccy).astype('float32')\n",
    "print(predsacc)\n",
    "print(predsaccy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUCROC Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = roc_auc_score(y_test, pred)\n",
    "print(\"The AUCROC Value : \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(predsaccy,predsacc)\n",
    "print(\"The F1 score : \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = classification_report(predsaccy, predsacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thresholds)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d56e60285a998055afbfb3b26b0788d5f3eeb1e121f88e1f4cd1a0324011c97b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('IITMLsesh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
